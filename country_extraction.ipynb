{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary modules\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import unicodedata\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.geocoders import GeoNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/charlotteout/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the geolocator\n",
    "geolocator = GeoNames(username = \"\") # omitted\n",
    "geocode = geocode = RateLimiter(geolocator.geocode,min_delay_seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset\n",
    "vegan_data = pd.read_csv('vegan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out the countries that have an empty location filed \n",
    "vegan_data_withloc = vegan_data[pd.notna(vegan_data['location'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a helper function used in the main function to remove the accents from the locations\n",
    "#to be able to match them with the values in the dictionary\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT: the datset including the vegan tweets and their respective locations\n",
    "#OUTPUT: the dataset including a column with the country matching the location\n",
    "\n",
    "#the function applied the GeoNames service to the location field in the dataset. \n",
    "#We then remove the accents and lowercase this string such that it matched the countries\n",
    "#defined in the \"countrylist\". If in an adress, we found a match between the country\n",
    "#specified in the adress and the countries in the countrylist, we add the \n",
    "#respective name of the country in english as specified in the countrydict \n",
    "#to the dataset \n",
    "\n",
    "def countryrecognition(dataset):\n",
    "    \n",
    "    \n",
    "    #list of countries in english and the respective local language that we want to recognize\n",
    "    countrylist = [\"netherlands\", 'nederland', 'sweden','sverige','ital','franc','norway'\n",
    "    , 'norge', 'iceland', 'island', 'brazil', 'brasil', 'russia',\n",
    "    'south africa', 'suid-afrika', 'india', 'switzerland', 'schweiz', \n",
    "    'suisse', 'svizzer', 'australia', 'austria', 'osterreich', \"belgi\",\n",
    "    'canada', 'chile', 'chzech', 'ceska', 'denmark', 'danmark', 'estonia',\n",
    "    'esti', 'finland', 'suomi', 'germany', 'deutschland', 'greece',\n",
    "    'hungary', 'magyarorsz', 'ireland', 'israel', 'japan', 'south korea',\n",
    "                   \"lavtiva\", 'latvija', 'lithuania', 'lietuva',\n",
    "                   'luxembourg', 'mexico', 'new zealand', 'poland',\n",
    "                   'polska', 'portugal', 'slovakia', 'slovensko',\n",
    "                   'sloveni', 'slovenia', 'spain', 'espana', 'turk',\n",
    "                   'kingdom', 'states', 'england', 'scotland', 'wales', 'great britain']\n",
    "                  \n",
    "    \n",
    "    #dictionary mapping the country found in the countrylist to the name of the country in\n",
    "    #english, as we want to have it in the dataset.\n",
    "    countrydict = {\n",
    "        'netherlands' : \"netherlands\",\n",
    "        'nederland' : \"netherlands\",\n",
    "        'sweden' : \"sweden\",\n",
    "        'sverige' : \"sweden\",\n",
    "        'ital' : \"italy\",\n",
    "        'franc' : \"france\",\n",
    "        'norway' : \"norway\",\n",
    "        'norge' : \"norway\",\n",
    "        'iceland' : \"iceland\",\n",
    "        'island' : \"iceland\",\n",
    "        'brazil' : \"brazil\",\n",
    "        'brasil' : \"brazil\",\n",
    "        'russia' : \"russia\",\n",
    "        'south africa' : \"south africa\",\n",
    "        'suid-afrika' : \"south africa\",\n",
    "        'india' : \"india\",\n",
    "        'switzerland' : \"switzerland\",\n",
    "        'schweiz' : \"switzerland\",\n",
    "        'suisse' : \"switzerland\",\n",
    "        'svizzer' : \"switzerland\",\n",
    "        'australia' : \"australia\",\n",
    "        'austria' : \"austria\",\n",
    "        'osterreich': \"austria\",\n",
    "        'belgi' : \"belgium\",\n",
    "        'canada' : \"canada\",\n",
    "        'chile' : \"chile\",\n",
    "        'chzech' : \"czech republic\",\n",
    "        'ceska' : \"czech republic\",\n",
    "        'denmark' : \"denmark\",\n",
    "        'danmark' : \"denmark\",\n",
    "        'estonia' : \"estonia\",\n",
    "        'esti' : \"estonia\",\n",
    "        'finland' : 'finland',\n",
    "        'suomi' : 'finland',\n",
    "        'germany' : 'germany',\n",
    "        'deutschland' : 'germany',\n",
    "        'greece' : 'greece',\n",
    "        'hungary' : 'hungary',\n",
    "        'magyarorsz' : 'hungary',\n",
    "        'ireland' : 'ireland',\n",
    "        'israel' : 'israel',\n",
    "        'japan' : 'japan',\n",
    "        'south korea': 'south korea',\n",
    "        'latvia' : 'latvia',\n",
    "        'lavtija' : 'latvia',\n",
    "        'lithuania' : 'lithuania',\n",
    "        'lietuva' : 'lithuania',\n",
    "        'luxembourg' : 'luxembourg',\n",
    "        'mexico' : 'mexico',\n",
    "        'new zealand' : 'new zealand',\n",
    "        'poland' : 'poland',\n",
    "        'polska': 'poland',\n",
    "        'portugal' : 'portugal',\n",
    "        'slovakia' : 'slovakia',\n",
    "        'slovensko' : 'slovakia',\n",
    "        'sloveni' : 'slovenia',\n",
    "        'slovenia' : 'slovenia',\n",
    "        'spain' : 'spain',\n",
    "        'espagna' : \"spain\",\n",
    "        'turk' : 'turkey',\n",
    "        'kingdom': \"united kingdom\",\n",
    "        'states' : 'united states',\n",
    "        'england' : 'united kingdom',\n",
    "        'scotland' : 'united kingdom',\n",
    "        'wales' : 'united kingdom',\n",
    "        'great britain' : 'united kingdom'\n",
    "    }              \n",
    "                  \n",
    "    \n",
    "    for row in range(np.shape(dataset)[0]):\n",
    "        \n",
    "        location = geolocator.geocode(dataset['location'].iloc[row])\n",
    "       \n",
    "        if location == None:\n",
    "            continue\n",
    "        else:\n",
    "            #remove the accents of the locations\n",
    "            unaccent_location = remove_accents(str(location))\n",
    "            #make the string lower case\n",
    "            location_string = str(unaccent_location).lower()\n",
    "            for country in countrylist:\n",
    "                #if it found one of the specified countries in the adress\n",
    "                if location_string.find(country) != -1:\n",
    "                    #add this country to the country column in the dataset\n",
    "                    dataset['country'].iloc[row] = countrydict.get(country)\n",
    "                    continue\n",
    "                else:\n",
    "                    continue\n",
    "                        \n",
    "    dataset.to_csv(SOME_LOCAL_PATH)\n",
    "                        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
